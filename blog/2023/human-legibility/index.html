<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Improving Human Legibility in Collaborative Robot Tasks through Augmented Reality and Workspace Preparation | Yi-Shiuan Tung</title> <meta name="author" content="Yi-Shiuan Tung"> <meta name="description" content="Improve human legibility by projecting virtual obstacles and rearranging objects in the workspace."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?e26219d56e20b1927be1ba2824b250be"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yi-shiuan-tung.github.io/blog/2023/human-legibility/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yi-Shiuan </span>Tung</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Improving Human Legibility in Collaborative Robot Tasks through Augmented Reality and Workspace Preparation</h1> <p class="post-meta">April 1, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="motivation">Motivation</h2> <p>The canonical approach for human robot interaction is to first predict the human motion and then generate a robot plan. This requires a robust and accurate predictions of human behavior. If the human models are inaccurate, the robot may produce unsafe interactions.</p> <p>To achieve more fluent human robot interaction, there has also been work on improving the robot’s expressiveness of its intentions. Dragan et al. developed a formalism for legibility which is the probability of successfully predicting an agent’s goal given an observation of a snippet of its trajectory <sup id="fnref:dragan_legibility" role="doc-noteref"><a href="#fn:dragan_legibility" class="footnote" rel="footnote">1</a></sup>. Subsequent works have shown that robots with legible movements lead to greater task efficiency, trustworthiness, and sense of safety in human robot collaboration. However, there hasn’t been work on looking at how human legibility can improve the robot’s ability to collaborate with humans.</p> <h2 id="our-approach">Our Approach</h2> <p>We improve the robot’s prediction of the human’s goal (aka the human’s legibility) by <strong>projecting virtual barriers in augmented reality and rearranging objects in the workspace</strong>. We present a metric that evaluates an environment configuration in terms of its legibility and present an optimization approach for autonomously generating object and virtual barrier placements.</p> <center> <img src="/blog/assets/img/human_legibility/legible_reach.jpg" alt="Tabletop Manipulation Task" width="300" style="margin-right:30px"> <img src="/blog/assets/img/human_legibility/navigation_exp.jpg" alt="Warehouse Navigation Task" width="310"> </center> <p><br></p> <h2 id="method">Method</h2> <h3 id="legibility-metric">Legibility Metric</h3> <p>First we define the legibility metric that scores an environment configuration in terms of how legibile it is to approach a goal.</p> <center> <img src="/blog/assets/img/human_legibility/env_leg_gt.png"> </center> <p>Given a ground truth goal $G_{true}$ (blue circle in the example below), we generate a snippet of the human’s trajectory approaching the blue circle. In our experiments we use <a href="https://en.wikipedia.org/wiki/Visibility_graph" rel="external nofollow noopener" target="_blank">visibility graphs</a>. If the most likely goal is not the blue circle, we penalize by a fixed cost $c$.</p> <center> <img src="/blog/assets/img/human_legibility/env_leg_fixed_cost.png" width="500"> </center> <p>If the robot is able to correctly predict the ground truth goal, we still want to award configurations with more confident predictions. Therefore, the score is the margin function which is the difference between the most likely and second most likely goal probabilities.</p> <center> <img src="/blog/assets/img/human_legibility/margin.png" width="380"> </center> <p><br></p> <h3 id="legibility-optimization">Legibility Optimization</h3> <p>Now that we can evaluate the legibility of an environment configuration given a ground truth goal, we present an objective function that evaluates the legibility for a task.</p> <p><br></p> <center> <img src="/blog/assets/img/human_legibility/leg_opt.png" width="500"> </center> <p><br></p> <p>We assume the task $T$ has general precedence constraints. A subtask can only begin after all of its precedence constraints are completed. For example, In an assembly task, you need to finish making the drawers before inserting them into their final positions. In the objective function, we iterate over all possible valid orderings of task $T$, which are the orderings that satisfy precedence constraints. We find the possible ground truth goals at a given state of a task and sum up the legibility scores (EnvLegibility).</p> <h3 id="quality-diversity-for-efficient-search">Quality Diversity for Efficient Search</h3> <p>Now that we know how to evaluate the legibility of a given workspace configuration, we need to search through the space of possible configurations to find the most legible one. This is computationally intractable for most non-trivial applications. We use a quality diversity approach called MAP-Elites <sup id="fnref:map_elites" role="doc-noteref"><a href="#fn:map_elites" class="footnote" rel="footnote">2</a></sup> to efficiently search through the space of possible workspace configurations.</p> <p>The MAP-Elites algorithm consists of two phases, the initialization phase and the improvement phase. In the initialization phase, a random environment is generated and placed in a grid where the dimensions of the grid are some features or behaviors of interest. Here we use the ordering of the cubes in the x-axis and the min distance between cubes. If two environments have the same cell in the grid, the one that has a higher legibility score is stored.</p> <center> <img src="/blog/assets/img/human_legibility/map_elites_init.png" width="300"> <figcaption>MAP-Elites Initialization</figcaption> </center> <p><br></p> <p>In the improvement phase, we sample a cell from the grid and run gradient descent. In gradient descent, we first sample new positions for each cube from a Gaussian centered at the cube’s current position. The new configuration may end up in a different cell in the grid. If the cell is not populated or if the new configuration has a better legibility score, then the new configuration is stored in the cell. Then, two cubes are randomly selected and a virtual obstacle of a fixed size is placed between them. We store the new configuration if the legibility score is better.</p> <center> <img src="/blog/assets/img/human_legibility/map_elites_improve.png" width="300"> <figcaption>MAP-Elites Improvement Phase</figcaption> </center> <p><br></p> <p>Below is a gif of the gradient descent process.</p> <center> <img src="/blog/assets/img/human_legibility/gradient_descent.gif" width="300"> </center> <h2 id="demo">Demo</h2> <iframe width="840" height="480" src="https://youtube.com/embed/QVV9SW4lyns" frameborder="0" allow="autoplay" allowfullscreen=""> </iframe> <p><br> <br></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:dragan_legibility" role="doc-endnote"> <p>A. D. Dragan, K. C. T. Lee and S. S. Srinivasa, “Legibility and predictability of robot motion,” 2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Tokyo, Japan, 2013, pp. 301-308, doi: 10.1109/HRI.2013.6483603. <a href="#fnref:dragan_legibility" class="reversefootnote" role="doc-backlink">↩</a></p> </li> <li id="fn:map_elites" role="doc-endnote"> <p>Mouret, Jean-Baptiste, and Jeff Clune. “Illuminating search spaces by mapping elites.” arXiv preprint arXiv:1504.04909 (2015). <a href="#fnref:map_elites" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yi-Shiuan Tung. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 23, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-509JKBBD7E"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-509JKBBD7E");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>